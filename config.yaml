model_list:
  - model_name: gemini-3-pro
    litellm_params:
      model: gemini/gemini-3-pro-preview
      api_key: os.environ/GEMINI_API_KEY
      # Automatic caching is supported for Gemini
  
  - model_name: gemini-3-flash
    litellm_params:
      model: gemini/gemini-3-flash-preview
      api_key: os.environ/GEMINI_API_KEY

  - model_name: gpt-5.2
    litellm_params:
      model: openai/gpt-5.2
      api_key: os.environ/OPENAI_API_KEY

  - model_name: gpt-5.1-mini
    litellm_params:
      model: openai/gpt-5.1-mini
      api_key: os.environ/OPENAI_API_KEY

  - model_name: claude-4.5-sonnet
    litellm_params:
      model: anthropic/claude-sonnet-4-5
      api_key: os.environ/ANTHROPIC_API_KEY
      cache_control_injection_points: 
        - role: system
          location: message

  - model_name: claude-4.5-opus
    litellm_params:
      model: anthropic/claude-opus-4-5
      api_key: os.environ/ANTHROPIC_API_KEY
      cache_control_injection_points: 
        - role: system
          location: message

  - model_name: claude-4.5-haiku
    litellm_params:
      model: anthropic/claude-haiku-4-5
      api_key: os.environ/ANTHROPIC_API_KEY
      cache_control_injection_points: 
        - role: system
          location: message



litellm_settings:
  drop_params: true
  guardrails:
    - anthropic-sanitizer:
        callbacks: ["guardrails.anthropic_guardrail.AnthropicGuardrail"]
        default_on: true
  # callbacks: ["otel", "langfuse"] # Example callbacks
